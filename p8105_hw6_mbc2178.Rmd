---
title: "p8105_hw6_mbc2178"
author: "Melvin Coleman"
date: "11/23/2022"
output: github_document
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(dplyr)
library(stringr)
library(modelr)
library(mgcv)
library(corrplot)

set.seed(1)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

### Problem 1 



### Problem 2 

Let's examine the Washington Post's data on homicides in 50 large U.S. cities. 
We will refer to this raw dataset as `homicide_df`.

```{r}
homicide_df =
  read_csv('data/homicide-data.csv', col_names = TRUE) 
```

The `homicide_df` contains data from 50 large cities in the U.S. with `r ncol(homicide_df)`
fields or variables and `r nrow(homicide_df)` records or observations. This dataset includes
first and last names as well as ethnicity of homicide victims (`victim_last`,`victim_first`,
`victim_race`), dates of homicide report (`reported_date`) and the status of cases characterized
as closed with arrest or closed without arrest (`disposition`). In addition, the 
dataset also contains the longitude (`lon`) and latitude (`lat`) of the cities 
where the homicide occurred. 

Let's perform some data cleaning and manipulation on `homicide_df` using the 
`janitor::clean_names()` and `mutate`. We ensured that `victim_age` is a numeric 
variable by using an `if_else` statement that would apply NA to all missing values.

New variables `city_state` and a binary variable `homicide_solved` with 0 and 1 to 
indicate whether the homicide is solved were created. In addition, we limit our 
analysis for those whose `victim_race` is white or black and exclude the following 
cities Dallas,TX,Phoenix, AZ, and Kansas City, MO because these don’t report victim 
race. Also, we omit Tulsa,AL because it is a data entry mistake.

```{r}
homicide_df =
  homicide_df %>% 
  janitor::clean_names() %>% 
  mutate(
    city_state = str_c(city,',',state),
    homicide_solved = if_else(disposition %in% c("Closed by arrest"), 1, 0),
    victim_age = ifelse(victim_age > 0, as.numeric(victim_age), NA)) %>% 
    
    filter(!city_state %in% c("Dallas,TX", "Phoenix, AZ", "Kansas City, MO","Tulsa,AL"),
           victim_race %in% c("White", "Black")) 
  
    
```

Let's now fit a logistic regression with resolved vs unresolved as the outcome and
victim age, sex and race as predictors for the city of Baltimore, MD. 

```{r}
baltimore_df = 
  homicide_df %>% 
  filter(city_state == "Baltimore,MD") %>% 
  select(victim_sex, victim_age, victim_race, homicide_solved, city_state) %>% 
  arrange(desc(homicide_solved))
  
```
Let's run the logistic regression in this step
```{r}
   
logfit_baltimore = 
  baltimore_df %>% 
  glm(homicide_solved ~ victim_age + victim_race + victim_sex, data = ., family = binomial()) 

```

Let's perform manipulations to obtain adjusted odds ratio estimates with 95% CI for 
solving homicides comparing male victims to female victims keeping all other variables fixed.


```{r}
logfit_baltimore %>% 
   broom::tidy() %>% 
  ## Exponentiate betas to obtain odds ratio & 95% CI
  mutate(
    log_OR = round(exp(estimate),3),
    CL_UpperLimit = round(exp(estimate + 1.96*std.error),3),
    CL_LowerLimit = round(exp(estimate - 1.96*std.error),3),
    term = str_replace(term, "^victim_sexMale", "Victim Sex: Male")) %>% 
  
     select(term, log_OR,CL_LowerLimit, CL_UpperLimit) %>% 
  
    filter(term == "Victim Sex: Male") %>% 
  rename('95%CI Upper Limit'= CL_UpperLimit ,
         '95%CI Lower Limit' = CL_LowerLimit,
         'Estimate' = log_OR,
          'Covariate' = term) %>% 
    knitr::kable(caption = "Table 1. Adjusted Odds Ratio for solving homicides <br>
                            (Adjusted for victim's age, race, and sex)", 
                            align = "cccc")

#### USE CONFINT to check if 95% CI calculations is correct 
```

Let's run a regression model for each of the cities in our `homicide_df` dataset
and extract the adjusted odds ratio (and CI) for solving homicides comparing male 
victims to female victims. We adjusted for victim's age, race, and sex.
We use `purrr:map` and `nest` to create a dataframe 
and apply the `glm` function to obtain estimated ORs and CIs for each city.

```{r}
cities_reg = 
  homicide_df %>% 
    nest(data = -city_state) %>% 
  mutate(
    models = map(data, ~glm(homicide_solved ~ victim_age + victim_race + victim_sex, data = .x, 
                            family = binomial())),
    results = map(models, broom::tidy)
  ) %>% 
     select(-data,-models) %>% 
       unnest(results) 
```

```{r}
cities_fit = 
  cities_reg %>% 
## Exponentiate betas to obtain odds ratio & 95% CI
  mutate(
    log_OR = round(exp(estimate),3),
    CL_UpperLimit = round(exp(estimate + 1.96*std.error),3),
    CL_LowerLimit = round(exp(estimate - 1.96*std.error),3),
    term = str_replace(term, "^victim_sexMale", "Victim Sex: Male")) %>% 
  
     select(city_state, term, log_OR,CL_LowerLimit, CL_UpperLimit) %>% 
  
    filter(term == "Victim Sex: Male") %>% 
    arrange(city_state) 


cities_fit %>% 
rename( 'Cities' = city_state, 
        '95%CI UpperLimit'= CL_UpperLimit ,
        '95%CI LowerLimit' = CL_LowerLimit,
         'Estimate' = log_OR,
         'Covariate' = term) %>% 
  
   knitr::kable(caption = "Table 2. Adjusted Odds Ratio for solving homicides in 50 cities <br>
                            (Adjusted for victim's age, race, and sex)", 
                align = "ccccc")
```

Below we create a plot that shows the estimated ORs and CIs for each city. The 
graph is organized by cities according to the estimated OR. 

```{r}
model_plot = 
  cities_fit %>% 
  arrange(log_OR) %>% 
  mutate(city_state = fct_reorder(city_state, log_OR)) %>% 
  
  ggplot(aes(x=city_state, y= log_OR)) + 
  geom_point() +
  
  ## Confidence Intervals 
  geom_errorbar(aes(ymin =CL_LowerLimit, ymax= CL_UpperLimit), width =.2, 
                position = position_dodge(0.05)) +
  
  ## Style format
labs(title = 
  "Adjusted Odds Ratio of unsolved homicides comparing males to females across U.S. 
              Cities (Adjusted for victim's age, race, and sex)") +
  xlab("Cities") +
  ylab("Adjusted Odds Ratios") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) 

model_plot

```
Comment on the graph!!!!!!

### Problem 3 

In this problem, we will analyze data gathered to understand the effects of several
variables on a child's birthweight. Let's load in our dataset and call it 
`birthwt_df`.

```{r}

birthwt_df = 
  read_csv("data/birthweight.csv") %>% 
  janitor::clean_names() %>% 
  
  ## convert numeric variables to factor 
  mutate(
    babysex = as.factor(babysex),
    mrace = as.factor(mrace),
    frace = as.factor(frace),
    malform = as.factor(malform)
  ) %>% 
  arrange()
  
```
For this problem, we will fit a model to examine the relationship between a child's
birthweight (`bwt`) and different factors. But in order to see what's correlated with 
our outcome and what factors we could examine in our model, let's create a 
correlation matrix. We removed all the categorical variables to produce our 
correlation matrix.

```{r}
 explo_df=
birthwt_df %>% 
  select(-babysex, -frace, -mrace, -malform)

corr_df= cor(explo_df)

corrplot(corr_df, method = "square")

```

From the correlation matrix, we observe a strong positive correlation between 
baby's birthweight measured in grams (`bwt`) , baby’s length at birth measured 
in centimeters(`blength`) and baby’s head circumference at birth measured in 
centimeters (`bhead`). In addition , there's also a fair positive correlation 
with gestational age in weeks (`gaweeks), mother's weight gain during pregnancy
(wtgain) and baby's birthweight.

Based on the information provided above, to model birthweight, we will examine 
the predictors `blength` and `bhead`. Let's fit our proposed model below.
```{r}
### MODEL 1
fit = lm(bwt ~ blength + bhead, data= birthwt_df)

fit %>% 
  broom::tidy() %>% 
    select(term, estimate, p.value) %>% 
       mutate(term = str_replace(term, "^blength", "Baby's length"),
              term = str_replace(term, "^bhead", "Head circumference")) %>% 
          knitr::kable(digits = 3)
```

Next, let's run regression diagnostics on our proposed model using the 
`modelr` package. We also produce graphics to visually inspect residuals and
fitted values.

```{r}
diagnostics_df = 
birthwt_df %>% 
  select(bwt, blength, bhead) %>% 
  modelr::add_predictions(fit) %>% 
  modelr::add_residuals(fit)

diagnostics_df %>% 
  ## Let's make of residuals against fitted values
  ggplot(aes(x = pred, y = resid)) +
    geom_point(alpha = 0.5) +
   geom_hline(yintercept = 0) +
  
   ## Style format
labs(title = 
  "Plot showing linear of residuals against fitted values (Model 1) ") +
   xlab("Predicted Values") +
   ylab("Residuals")
  
```

From the graph above, we observe that our points/errors are randomly distributed 
across our true mean and satisfies our assumptions. However, it's worth mentioning
that there are a few outliers in our model and we should be cautions about what 
steps we take to address them in our final model. 


Next, let's compare our first model to two others: <br>
- One using length at birth and gestational age as predictors (main effects only) <br>
- One using head circumference, length, sex, and all interactions 
  (including the three-way interaction) between these

We make this comparison by using cross validation making use of `crossv_mc` and 
`purrr` packages. We first split our dataset into training and testing datasets.

```{r}

cv_df = 
  crossv_mc(birthwt_df, 100) 
```

```{r}
cv_df = 
  cv_df %>% 
  mutate(
    ## MODEL 1
    model1 = map(train, ~lm(bwt ~ blength + bhead, data = .x)),
    
    ## MODEL 2
    model2=  map(train, ~lm(bwt ~ blength + gaweeks, data = .x))) %>% 
  
    ## MODEL 3
  ##  model3=  map(train, ~lm(bwt ~ bhead + blength + babysex data = .x))) %>% 
  mutate(
    rmse_model1 = map2_dbl(model1, test, ~rmse(model = .x, data = .y)),
    rmse_model2 = map2_dbl(model2, test, ~rmse(model = .x, data = .y))) 
    ##rmse_model3 = map2_dbl(model3, test, ~rmse(model = .x, data = .y))
```

Make this comparison in terms of the cross-validated prediction error; use crossv_mc and functions in purrr as appropriate

```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```





